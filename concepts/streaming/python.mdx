---
title: Python Streaming
---

Chainlit supports streaming with any Python code. Here is an example with `openai`.

## OpenAI Completion

````python Code Example
import openai
import chainlit as cl

openai.api_key = "YOUR_API_KEY"

model_name = "text-davinci-003"

settings = {
    "temperature": 0.7,
    "max_tokens": 500,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0,
    "stop": ["```"],
}

prompt = """Answer the following question:
{question}
"""


@cl.on_message
def main(message: str):
    fromatted_prompt = prompt.format(question=message)
    msg = cl.Message(
        content="",
        prompt=fromatted_prompt,
        llm_settings=cl.LLMSettings(model_name=model_name, **settings),
    )

    for resp in openai.Completion.create(
        model=model_name, prompt=fromatted_prompt, stream=True, **settings
    ):
        token = resp.choices[0].text
        msg.stream_token(token)

    msg.send()
````

## OpenAI Chat Completion

```python Code Example
import openai
import chainlit as cl

openai.api_key = "YOUR_API_KEY"

model_name = "gpt-3.5-turbo"
settings = {
    "temperature": 0.7,
    "max_tokens": 500,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0,
}


@cl.on_chat_start
def start_chat():
    cl.user_session.set(
        "message_history",
        [{"role": "system", "content": "You are a helpful assistant."}],
    )


@cl.on_message
def main(message: str):
    message_history = cl.user_session.get("message_history")
    message_history.append({"role": "user", "content": message})

    msg = cl.Message(content="")

    response = openai.ChatCompletion.create(
        model=model_name, messages=message_history, stream=True, **settings
    )
    for resp in response:
        token = resp.choices[0]["delta"].get("content", "")
        msg.stream_token(token)

    message_history.append({"role": "assistant", "content": msg.content})
    msg.send()
```
