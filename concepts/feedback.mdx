---
title: Human Feedback
---

Chainlit apps can be leveraged as sandboxed environments to collect feedback on your LLM-based app from your team or users.

Human feedback is a crucial part of developing your LLM app or agent. 
It allows your users to provide direct feedback on the interaction, which can be used to improve the performance and accuracy of your system. By enabling data persistence, each message sent by your application will be accompanied by thumbs up and thumbs down icons.


## Benefits

- **Dataset Creation:** Feedback interactions implicitly generate valuable training data to improve the agent's responses over time.

- **Accuracy Measurement:** Feedback scores enable objective measurement and comparison of different agent versions, facilitating continuous model improvement.

- **User-Centric Development:** Direct feedback promotes a user-centric approach, ensuring the model evolves to meet user needs and expectations.

- **Training and Fine-Tuning:** Human feedback allows for direct model training and fine-tuning based on specific interactions.

## How-to

To use human feedback, you first need to enable [data persistence](/cloud/persistence/cloud). 

Once data persistence is enabled, each message sent by your application will be accompanied by thumbs up and thumbs down icons. Users can click these icons to provide feedback on the interaction.

<Frame caption="Human feedback">
  <img src="/images/human-feedback.gif" />
</Frame>

If you are using custom data persistence, the logic for the feedback provided by the user should be written within the `set_human_feedback` method (more info [here](/cloud/persistence/custom)).

```py
async def set_human_feedback(
    self, message_id: int, feedback: Literal[-1, 0, 1]
) -> bool:
    raise NotImplementedError
```

## Conclusion

Human feedback is a powerful tool for improving the performance of your LLM app. By enabling data persistence and collecting feedback, you can create a dataset that can be used to improve the system's accuracy.


