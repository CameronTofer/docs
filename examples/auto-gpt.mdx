---
title: Auto GPT
---

Example inspired from the [LangChain doc](https://python.langchain.com/en/latest/use_cases/autonomous_agents/autogpt.html)

## Code
```python
from langchain.utilities import SerpAPIWrapper
from langchain.agents import Tool
from langchain.tools.file_management.write import WriteFileTool
from langchain.tools.file_management.read import ReadFileTool

search = SerpAPIWrapper()
tools = [
    Tool(
        name = "search",
        func=search.run,
        description="useful for when you need to answer questions about current events. You should ask targeted questions"
    ),
    WriteFileTool(),
    ReadFileTool(),
]

from langchain.vectorstores import FAISS
from langchain.docstore import InMemoryDocstore
from langchain.embeddings import OpenAIEmbeddings

# Define your embedding model
embeddings_model = OpenAIEmbeddings()
# Initialize the vectorstore as empty
import faiss

embedding_size = 1536
index = faiss.IndexFlatL2(embedding_size)

from langchain.experimental import AutoGPT
from langchain.chat_models import ChatOpenAI
from chainlit import langchain_factory, langchain_run

@langchain_factory
def agent():
    vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})
    agent = AutoGPT.from_llm_and_tools(
        ai_name="Tom",
        ai_role="Assistant",
        tools=tools,
        llm=ChatOpenAI(temperature=0, streaming=True),
        memory=vectorstore.as_retriever()
    )
    # Set verbose to be true
    agent.chain.verbose = True
    return agent

@langchain_run
def run(agent, input):
    return agent.run([input])
```

## Result:
![QA](/images/auto-gpt.png)